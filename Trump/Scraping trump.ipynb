{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press ENTER to get started.\n",
      "Let's go...\n",
      "Next page not found. Terminating script.\n",
      "Done...I think\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import time\n",
    "if False:\n",
    "    def get_transcript():\n",
    "\n",
    "        return\n",
    "\n",
    "    def go_back():\n",
    "        driver.execute_script(\"window.history.go(-1)\")\n",
    "\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    driver.get(\"https://www.rev.com/blog/transcript-category/donald-trump-transcripts?view=all\")\n",
    "\n",
    "    input(\"Press ENTER to get started.\")\n",
    "    print(\"Let's go...\")\n",
    "    links = []\n",
    "    while True:\n",
    "        #Getting next page info to the next page\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//a[contains(@class,'next page-numbers')]\")))\n",
    "            next_page_link = driver.find_element_by_xpath(\"//a[contains(@class,'next page-numbers')]\").get_attribute(\"href\")\n",
    "\n",
    "        except:\n",
    "            print(\"Next page not found. Terminating script.\")\n",
    "            next_page_link = False\n",
    "\n",
    "\n",
    "\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[contains(@class,'pa3 f5')]\")))\n",
    "\n",
    "        speeches_elements = driver.find_elements_by_xpath(\"//div[contains(@class,'pa3 f5')]\")\n",
    "        page_links = []\n",
    "        time.sleep(5)\n",
    "\n",
    "        for speech in speeches_elements:\n",
    "            currentLink = speech.find_element_by_xpath(\"../..\")\n",
    "            href = currentLink.get_attribute(\"href\")\n",
    "            page_links.append(href)\n",
    "\n",
    "        links.extend(page_links)\n",
    "        \"\"\"\n",
    "        for link in page_links:\n",
    "\n",
    "            driver.get(link)\n",
    "\n",
    "            driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + 'w')\n",
    "            time.sleep(1)\n",
    "            #get_transcript()\n",
    "\n",
    "            driver.execute_script(\"window.history.go(-1)\")\n",
    "        \"\"\"\n",
    "        if next_page_link:\n",
    "            driver.get(next_page_link)\n",
    "        else:\n",
    "            print(\"Done...I think\")\n",
    "            break\n",
    "\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = reversed(links)\n",
    "with open(\"transcriptURL_old_to_new.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "\n",
    "HTML_FOLDER = \"transcriptHTML\"\n",
    "if False:\n",
    "    if \"links\" not in globals():\n",
    "        with open(\"transcriptURL_old_to_new.txt\", \"r\") as file:\n",
    "            links = file.read().split(\"\\n\")\n",
    "\n",
    "    for index, link in enumerate(links):\n",
    "        response = requests.get(link)\n",
    "\n",
    "        file_name = \"speech_number_{}.html\".format(str(index+1).zfill(4))\n",
    "        with open(os.path.join(HTML_FOLDER, file_name), \"w\", encoding = \"utf-8\") as file:\n",
    "            file.write(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Inches, Pt, RGBColor\n",
    "from docx.enum.style import WD_STYLE_TYPE\n",
    "from docx.text.run import Font, Run\n",
    "from docx.enum.text import WD_BREAK\n",
    "\n",
    "\n",
    "## Now getting the HTML files, parsing them and writing into the document\n",
    "if True:\n",
    "    file_names = os.listdir(HTML_FOLDER)\n",
    "\n",
    "    document = Document()\n",
    "    \n",
    "    styles = document.styles\n",
    "    style = styles.add_style(\"Trump\", WD_STYLE_TYPE.CHARACTER)\n",
    "    font = style.font\n",
    "    font.name = \"Comic Sans MS\"\n",
    "    font.size = Pt(11)    \n",
    "    \n",
    "    \"Copperplate\"\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        with open(os.path.join(HTML_FOLDER, file_name), encoding = \"utf-8\") as f:\n",
    "            contents = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(contents, 'lxml')\n",
    "        \n",
    "        #Title\n",
    "        title_trimmed = re.sub(' - Rev$', '', soup.title.string)\n",
    "        \n",
    "        document.add_heading(title_trimmed, 1)\n",
    "        \n",
    "        body = soup.find(\"div\", {\"class\": \"fl-callout-text\"})\n",
    "        children = body.findChildren(\"p\")\n",
    "        trump_speaking = False\n",
    "        \n",
    "        for p in children:\n",
    "            p_list = p.get_text().split(\"\\n\")\n",
    "            speaker_line = p_list[0]\n",
    "            speaker_section = \"\\n\".join(p_list[1:])\n",
    "            \n",
    "            if \"Trump\" in speaker_line:\n",
    "                trump_speaking = True\n",
    "            else:\n",
    "                trump_speaking = False\n",
    "            \n",
    "            \n",
    "            para = document.add_paragraph()\n",
    "            para.add_run(speaker_line).bold = True\n",
    "            para.add_run().add_break()\n",
    "            \n",
    "            if trump_speaking:\n",
    "                para.add_run(speaker_section, style = styles[\"Trump\"])\n",
    "            else:\n",
    "                para.add_run(speaker_section)\n",
    "            \n",
    "            \"\"\"\n",
    "            print(speaker_line)\n",
    "            print(\"=======\")\n",
    "            print(speaker_section)\n",
    "            print(\"+++++++++++\\n+++++++++++++\")\n",
    "            \"\"\"\n",
    "        para.add_run().add_break(WD_BREAK.PAGE)\n",
    "    document.save('Bible a la Trump AUTOGEN.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now getting the HTML files, parsing them and writing into the document\n",
    "if True:\n",
    "    file_names = os.listdir(HTML_FOLDER)\n",
    "\n",
    "    #trump_bible = Document()\n",
    "    \n",
    "    for file_name in file_names[:1]:\n",
    "        with open(os.path.join(HTML_FOLDER, file_name), encoding = \"utf-8\") as f:\n",
    "            contents = f.read()\n",
    "\n",
    "        soup = BeautifulSoup(contents, 'lxml')\n",
    "        \n",
    "        #Title\n",
    "        print(re.sub(' - Rev$', '', soup.title.string))\n",
    "        #document.add_heading(soup.title, 0)\n",
    "        \n",
    "        body = soup.find(\"div\", {\"class\": \"fl-callout-text\"})\n",
    "        \n",
    "        for p in body:\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "document = Document()\n",
    "\n",
    "document.add_heading('Document Title', 0)\n",
    "\n",
    "p = document.add_paragraph('A plain paragraph having some ')\n",
    "p.add_run('bold').bold = True\n",
    "p.add_run(' and some ')\n",
    "p.add_run('italic.').italic = True\n",
    "\n",
    "document.add_heading('Heading, level 1', level=1)\n",
    "document.add_paragraph('Intense quote', style='Intense Quote')\n",
    "\n",
    "document.add_paragraph(\n",
    "    'first item in unordered list', style='List Bullet'\n",
    ")\n",
    "document.add_paragraph(\n",
    "    'first item in ordered list', style='List Number'\n",
    ")\n",
    "\n",
    "\n",
    "records = (\n",
    "    (3, '101', 'Spam'),\n",
    "    (7, '422', 'Eggs'),\n",
    "    (4, '631', 'Spam, spam, eggs, and spam')\n",
    ")\n",
    "\n",
    "table = document.add_table(rows=1, cols=3)\n",
    "hdr_cells = table.rows[0].cells\n",
    "hdr_cells[0].text = 'Qty'\n",
    "hdr_cells[1].text = 'Id'\n",
    "hdr_cells[2].text = 'Desc'\n",
    "for qty, id, desc in records:\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = str(qty)\n",
    "    row_cells[1].text = id\n",
    "    row_cells[2].text = desc\n",
    "\n",
    "document.add_page_break()\n",
    "\n",
    "document.save('demo.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
